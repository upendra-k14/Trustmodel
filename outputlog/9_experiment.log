impact of homophily term
Generating negative set...
Variables initialized
Loss: 11997.2734375
Loss: 11723.970703125
Loss: 11691.61328125
Loss: 11812.1767578125
Loss: 11714.140625
Loss: 11671.3564453125
Loss: 11422.978515625
Loss: 11449.931640625
Loss: 11325.5478515625
Loss: 11352.9150390625
Loss: 11180.400390625
Loss: 11169.703125
Loss: 11151.306640625
Loss: 10978.6240234375
Loss: 10947.1474609375
Loss: 10705.5224609375
Loss: 10608.7705078125
Loss: 10546.61328125
Loss: 10603.7177734375
Loss: 10586.279296875
Loss: 10500.44140625
Loss: 10320.9609375
Loss: 10311.6494140625
Loss: 10205.4990234375
Loss: 10083.4189453125
-----------------------------------------
Iteration 250
Test Accuracy: 0.3219158264895061
-----------------------------------------
-----------------------------------------
Iteration 250
Train Accuracy: 0.471782520567545
-----------------------------------------
Loss: 99984.078125
Loss: 86034.5625
Loss: 75818.9453125
Loss: 66459.765625
Loss: 58794.21875
Loss: 51892.26953125
Loss: 45805.5625
Loss: 39545.78125
Loss: 35795.0390625
Loss: 30962.287109375
Loss: 27658.15234375
Loss: 24683.76171875
Loss: 21599.5625
Loss: 19622.125
Loss: 17717.01171875
Loss: 16047.994140625
Loss: 14552.205078125
Loss: 13268.0
Loss: 12326.7626953125
Loss: 11621.623046875
Loss: 10988.3349609375
Loss: 10379.974609375
Loss: 9972.513671875
Loss: 9610.978515625
Loss: 9227.0595703125
-----------------------------------------
Iteration 500
Test Accuracy: 0.23392535220671695
-----------------------------------------
-----------------------------------------
Iteration 500
Train Accuracy: 0.0757982592106832
-----------------------------------------
Loss: 9146.2822265625
Loss: 8870.5
Loss: 8583.9912109375
Loss: 8480.6484375
Loss: 8194.2978515625
Loss: 8100.130859375
Loss: 7851.044921875
Loss: 7766.88671875
Loss: 7676.2080078125
Loss: 7572.751953125
Loss: 7380.88623046875
Loss: 7346.86328125
Loss: 7183.68310546875
Loss: 6931.60693359375
Loss: 6867.21484375
Loss: 6824.4326171875
Loss: 6723.47265625
Loss: 6707.8134765625
Loss: 6526.7177734375
Loss: 6445.50634765625
Loss: 6432.89501953125
Loss: 6217.2001953125
Loss: 6177.72998046875
Loss: 6121.3017578125
Loss: 5981.8408203125
-----------------------------------------
Iteration 750
Test Accuracy: 0.3803164852774254
-----------------------------------------
-----------------------------------------
Iteration 750
Train Accuracy: 0.41429354954095626
-----------------------------------------
Loss: 5877.29150390625
Loss: 5790.00341796875
Loss: 5689.5185546875
Loss: 5650.45849609375
Loss: 5541.97509765625
Loss: 5441.275390625
Loss: 5418.15771484375
Loss: 5361.42626953125
Loss: 5244.05615234375
Loss: 5123.732421875
Loss: 5049.55126953125
Loss: 4993.4931640625
Loss: 4966.1943359375
Loss: 4845.17431640625
Loss: 4825.81005859375
Loss: 4697.94287109375
Loss: 4750.7939453125
Loss: 4605.369140625
Loss: 4514.4736328125
Loss: 4497.39892578125
Loss: 4404.51416015625
Loss: 4323.55712890625
Loss: 4281.923828125
Loss: 4250.30322265625
Loss: 4152.62744140625
-----------------------------------------
Iteration 1000
Test Accuracy: 0.40120406846052836
-----------------------------------------
-----------------------------------------
Iteration 1000
Train Accuracy: 0.5417193275307023
-----------------------------------------
Loss: 4083.705322265625
Loss: 4009.3369140625
Loss: 3961.634033203125
Loss: 3886.008544921875
Loss: 3739.8046875
Loss: 3698.830078125
Loss: 3548.080810546875
Loss: 3544.80859375
Loss: 3480.72802734375
Loss: 3286.932373046875
Loss: 3151.380615234375
Loss: 3006.790283203125
Loss: 2905.723388671875
Loss: 2870.27392578125
Loss: 2601.809814453125
Loss: 2521.6103515625
Loss: 2376.0009765625
Loss: 1914.3446044921875
Loss: 1603.177734375
Loss: 1512.221435546875
Loss: 954.55224609375
Loss: -150.741943359375
Loss: -93.8134765625
Loss: -873.139892578125
Loss: -1317.1748046875
-----------------------------------------
Iteration 1250
Test Accuracy: 0.3742850148004718
-----------------------------------------
-----------------------------------------
Iteration 1250
Train Accuracy: 0.4751591749135567
-----------------------------------------
Loss: -2607.174560546875
Loss: -3130.281005859375
Loss: -4604.501953125
Loss: -5128.21142578125
Loss: -7701.8134765625
Loss: -8715.2060546875
Loss: -10605.1171875
Loss: -12871.625
