impact of homophily term
Generating negative set...
Variables initialized
Loss: 11955.1865234375
Loss: 11919.8212890625
Loss: 11687.2109375
Loss: 11708.5283203125
Loss: 11520.201171875
Loss: 11612.2705078125
Loss: 11537.38671875
Loss: 11419.5234375
Loss: 11246.4775390625
Loss: 11135.529296875
Loss: 11248.2890625
Loss: 11118.111328125
Loss: 11078.2060546875
Loss: 10925.732421875
Loss: 10921.1396484375
Loss: 10811.974609375
Loss: 10676.2705078125
Loss: 10643.1181640625
Loss: 10415.92578125
Loss: 10516.787109375
Loss: 10284.380859375
Loss: 10528.9716796875
Loss: 10240.34765625
Loss: 10098.7314453125
Loss: 10113.5341796875
-----------------------------------------
Iteration 250
Test Accuracy: 0.3171752242327124
-----------------------------------------
-----------------------------------------
Iteration 250
Train Accuracy: 0.4721259091451055
-----------------------------------------
Loss: 10725.6494140625
Loss: 10680.1728515625
Loss: 10585.3291015625
Loss: 10464.63671875
Loss: 10393.306640625
Loss: 10421.1005859375
Loss: 10263.4091796875
Loss: 10043.2490234375
Loss: 9894.005859375
Loss: 9898.6318359375
Loss: 9804.822265625
Loss: 9609.6328125
Loss: 9407.36328125
Loss: 9352.9658203125
Loss: 9196.4453125
Loss: 9074.2353515625
Loss: 8992.630859375
Loss: 8873.90234375
Loss: 8718.3994140625
Loss: 8650.173828125
Loss: 8413.4541015625
Loss: 8498.421875
Loss: 8251.544921875
Loss: 8131.62744140625
Loss: 8143.05078125
-----------------------------------------
Iteration 500
Test Accuracy: 0.380772740424206
-----------------------------------------
-----------------------------------------
Iteration 500
Train Accuracy: 0.5258471443901276
-----------------------------------------
Loss: 7842.80517578125
Loss: 7916.091796875
Loss: 7792.0341796875
Loss: 7675.6298828125
Loss: 7770.4140625
Loss: 7749.89306640625
Loss: 7480.0830078125
Loss: 7550.8369140625
Loss: 7493.0712890625
Loss: 7328.4677734375
Loss: 7277.67041015625
Loss: 7185.98974609375
Loss: 7087.29833984375
Loss: 7146.8515625
Loss: 7072.95361328125
Loss: 6799.9462890625
Loss: 6908.88134765625
Loss: 6841.31201171875
Loss: 6870.00732421875
Loss: 6768.388671875
Loss: 6619.29638671875
Loss: 6559.666015625
Loss: 6549.05712890625
Loss: 6431.94091796875
Loss: 6328.98876953125
-----------------------------------------
Iteration 750
Test Accuracy: 0.379047873405889
-----------------------------------------
-----------------------------------------
Iteration 750
Train Accuracy: 0.5830118039823536
-----------------------------------------
Loss: 6345.86474609375
Loss: 6267.39453125
Loss: 6107.07275390625
Loss: 6148.8154296875
Loss: 6108.5166015625
Loss: 5964.51806640625
Loss: 5740.68798828125
Loss: 5886.80419921875
Loss: 5671.7646484375
Loss: 5568.013671875
Loss: 5612.93603515625
Loss: 5538.5927734375
Loss: 5427.74169921875
Loss: 5406.5947265625
Loss: 5327.0888671875
Loss: 5173.29345703125
Loss: 5137.49560546875
Loss: 5062.21875
Loss: 4928.44970703125
Loss: 4933.4365234375
Loss: 4839.86865234375
Loss: 4758.77880859375
Loss: 4737.95361328125
Loss: 4664.9814453125
Loss: 4572.39013671875
-----------------------------------------
Iteration 1000
Test Accuracy: 0.388751641405711
-----------------------------------------
-----------------------------------------
Iteration 1000
Train Accuracy: 0.6107070466197687
-----------------------------------------
Loss: 4485.7548828125
Loss: 4547.3671875
Loss: 4485.6953125
Loss: 4391.03125
Loss: 4384.734375
Loss: 4377.16650390625
Loss: 4343.5966796875
Loss: 4217.02099609375
Loss: 4231.1396484375
Loss: 4247.50732421875
Loss: 4169.52685546875
Loss: 4080.126220703125
Loss: 4092.13671875
Loss: 4073.601806640625
Loss: 4035.88525390625
Loss: 3966.29296875
Loss: 3950.575439453125
Loss: 3881.142333984375
Loss: 3849.4755859375
Loss: 3793.4931640625
Loss: 3737.50927734375
Loss: 3698.277099609375
Loss: 3792.443603515625
Loss: 3631.766845703125
Loss: 3658.952880859375
-----------------------------------------
Iteration 1250
Test Accuracy: 0.3681200062317776
-----------------------------------------
-----------------------------------------
Iteration 1250
Train Accuracy: 0.6092237987361393
-----------------------------------------
Loss: 3615.379638671875
Loss: 3593.925537109375
Loss: 3493.532470703125
Loss: 3497.97802734375
Loss: 3427.37060546875
Loss: 3380.65625
Loss: 3316.159423828125
Loss: 3233.70458984375
Loss: 3190.98291015625
Loss: 3162.628662109375
Loss: 3132.62353515625
Loss: 3091.926513671875
Loss: 3041.560546875
Loss: 3041.115966796875
Loss: 2963.779541015625
Loss: 2950.070068359375
Loss: 2901.7421875
Loss: 2823.88134765625
Loss: 2841.3134765625
Loss: 2774.865234375
Loss: 2752.67529296875
Loss: 2703.229248046875
Loss: 2639.209716796875
Loss: 2631.030029296875
Loss: 2613.214111328125
-----------------------------------------
Iteration 1500
Test Accuracy: 0.35851639180076117
-----------------------------------------
-----------------------------------------
Iteration 1500
Train Accuracy: 0.6076737808513175
-----------------------------------------
##########################################
Margin 1.0
a1 1.0, a2 1.0, a3 0.1 a4 0.001
Average accuracy 0.36539731291684285
Number of iterations 1501
##########################################
Generating negative set...
Variables initialized
Loss: 11884.759765625
Loss: 11744.0458984375
Loss: 11886.529296875
Loss: 11754.470703125
Loss: 11826.4091796875
Loss: 11622.8037109375
Loss: 11617.9658203125
Loss: 11499.98828125
Loss: 11323.119140625
Loss: 11270.7607421875
Loss: 11288.404296875
Loss: 11078.875
Loss: 10981.8779296875
Loss: 10859.833984375
Loss: 10998.1025390625
Loss: 10891.666015625
Loss: 10618.484375
Loss: 10543.6494140625
Loss: 10623.0166015625
Loss: 10549.052734375
Loss: 10327.310546875
Loss: 10408.7705078125
Loss: 10255.783203125
Loss: 10156.6220703125
Loss: 10109.58984375
-----------------------------------------
Iteration 250
Test Accuracy: 0.30900714428790815
-----------------------------------------
-----------------------------------------
Iteration 250
Train Accuracy: 0.47383808274710865
-----------------------------------------
Loss: 17716.46875
Loss: 16780.111328125
Loss: 15794.1640625
Loss: 15086.9296875
Loss: 14151.875
Loss: 13466.30078125
Loss: 12955.9443359375
Loss: 12283.556640625
Loss: 12009.185546875
Loss: 11411.482421875
Loss: 11240.509765625
Loss: 10874.623046875
Loss: 10524.470703125
Loss: 10143.9111328125
Loss: 9990.951171875
Loss: 9659.1787109375
Loss: 9481.2353515625
Loss: 9237.07421875
Loss: 8943.466796875
Loss: 8862.611328125
Loss: 8789.966796875
Loss: 8556.65234375
Loss: 8328.169921875
Loss: 8285.5830078125
Loss: 8117.66455078125
-----------------------------------------
Iteration 500
Test Accuracy: 0.3399657252231199
-----------------------------------------
-----------------------------------------
Iteration 500
Train Accuracy: 0.367182544413974
-----------------------------------------
Loss: 7731.1396484375
Loss: 7741.32373046875
Loss: 7675.96240234375
Loss: 7644.140625
Loss: 7546.48046875
Loss: 7447.1083984375
Loss: 7287.70166015625
Loss: 7307.99169921875
Loss: 7362.5546875
Loss: 7229.82958984375
Loss: 7097.173828125
Loss: 7128.845703125
Loss: 6897.0595703125
Loss: 6849.71142578125
Loss: 6846.0751953125
Loss: 6802.68701171875
Loss: 6714.513671875
Loss: 6595.607421875
Loss: 6641.00537109375
Loss: 6507.9716796875
Loss: 6428.3056640625
Loss: 6426.068359375
Loss: 6371.63916015625
Loss: 6320.80810546875
Loss: 6206.01123046875
-----------------------------------------
Iteration 750
Test Accuracy: 0.3965079789009815
-----------------------------------------
-----------------------------------------
Iteration 750
Train Accuracy: 0.5613354000238464
-----------------------------------------
Loss: 6193.23974609375
Loss: 6090.1396484375
Loss: 6029.08935546875
Loss: 5958.73876953125
Loss: 5897.35791015625
Loss: 5679.13818359375
Loss: 5701.14111328125
Loss: 5635.3974609375
Loss: 5523.56640625
Loss: 5480.07763671875
Loss: 5394.92236328125
Loss: 5289.2646484375
Loss: 5265.80859375
Loss: 5187.763671875
Loss: 5091.03564453125
Loss: 4998.1640625
Loss: 4936.91015625
Loss: 4909.07373046875
Loss: 4893.7900390625
Loss: 4756.8447265625
Loss: 4685.69287109375
Loss: 4655.26123046875
Loss: 4568.87890625
Loss: 4451.39404296875
Loss: 4426.912109375
-----------------------------------------
Iteration 1000
Test Accuracy: 0.41311121497407133
-----------------------------------------
-----------------------------------------
Iteration 1000
Train Accuracy: 0.610034577322046
-----------------------------------------
Loss: 4391.3515625
Loss: 4368.244140625
Loss: 4339.6484375
Loss: 4310.93310546875
Loss: 4237.505859375
Loss: 4220.4560546875
Loss: 4226.5107421875
Loss: 4182.5078125
Loss: 4188.416015625
Loss: 3963.40478515625
Loss: 4035.880615234375
Loss: 4004.40576171875
Loss: 3937.021484375
Loss: 3887.840576171875
Loss: 3858.639892578125
Loss: 3888.4462890625
Loss: 3813.571533203125
Loss: 3713.71044921875
Loss: 3738.957275390625
Loss: 3706.181396484375
Loss: 3655.611572265625
Loss: 3675.963623046875
Loss: 3576.534912109375
Loss: 3573.015869140625
Loss: 3521.77587890625
-----------------------------------------
Iteration 1250
Test Accuracy: 0.38937481916716743
-----------------------------------------
-----------------------------------------
Iteration 1250
Train Accuracy: 0.615643257422201
-----------------------------------------
Loss: 3497.8701171875
Loss: 3443.100830078125
Loss: 3369.640869140625
Loss: 3396.263671875
Loss: 3265.821533203125
Loss: 3243.195068359375
Loss: 3246.83203125
Loss: 3146.560791015625
Loss: 3114.49462890625
Loss: 3048.76171875
Loss: 3013.619384765625
Loss: 3027.048095703125
Loss: 2972.002197265625
Loss: 2984.8115234375
Loss: 2839.59423828125
Loss: 2863.96240234375
Loss: 2837.103515625
Loss: 2819.50634765625
Loss: 2716.470458984375
Loss: 2714.194091796875
Loss: 2611.93505859375
Loss: 2612.38916015625
Loss: 2632.429443359375
Loss: 2566.409423828125
Loss: 2495.604736328125
-----------------------------------------
Iteration 1500
Test Accuracy: 0.37013420578219935
-----------------------------------------
-----------------------------------------
Iteration 1500
Train Accuracy: 0.6130058423751044
-----------------------------------------
##########################################
Margin 1.0
a1 1.0, a2 1.0, a3 0.1 a4 0.01
Average accuracy 0.3696835147225746
Number of iterations 1501
##########################################
